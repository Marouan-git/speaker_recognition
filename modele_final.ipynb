{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import IPython.display as ipd\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import librosa\n",
    "from IPython.display import Audio\n",
    "import numpy\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import os\n",
    "import scipy.signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['marouan.wav', '.DS_Store', 'marouan1.wav']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(\"Marouan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "aissa_audios = []\n",
    "\n",
    "\n",
    "for file in os.listdir(\"Aissa\"):\n",
    "\n",
    "    # Charger l'audio dans la liste aissa audios\n",
    "    audio_aissa, sr_aissa = librosa.load(\"Aissa/\" + file)\n",
    "    aissa_audios.append(audio_aissa)\n",
    "\n",
    "\n",
    "\n",
    "marouan_audios = []\n",
    "\n",
    "for file in os.listdir(\"Marouan\"):\n",
    "    # Changer l'audio dans la liste aissa audios\n",
    "    audio_marouan, sr_marouan = librosa.load(\"Marouan/\" + file)\n",
    "    marouan_audios.append(audio_marouan)\n",
    "\n",
    "\n",
    "\n",
    "autre_audios = []\n",
    "\n",
    "\n",
    "for file in os.listdir(\"Autre\"):\n",
    "    # Changer l'audio dans la liste aissa audios\n",
    "    audio_autre, sr_autre = librosa.load(\"Autre/\" + file)\n",
    "\n",
    "    autre_audios.append(audio_autre)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretraitment(sound):\n",
    "    sound_filtered = pass_band_filter(sound)\n",
    "    sound_no_silence = remove_silence(sound_filtered)\n",
    "    return sound_no_silence\n",
    "\n",
    "def remove_silence(signal):\n",
    "    # extract non-silent intervals from the voice signal\n",
    "    voice_intervals = librosa.effects.split(signal, frame_length=2048, top_db=50, hop_length=512)\n",
    "    voice_no_silence = np.array([])\n",
    "    slices = [signal[interval[0]:interval[1]] for interval in voice_intervals]\n",
    "    voice_no_silence = np.concatenate(slices)\n",
    "    return voice_no_silence\n",
    "\n",
    "def pass_band_filter(sound, sr_sound=22050):\n",
    "    # design a filter to remove the background noise using `scipy.signal.iirfilter`\n",
    "    b, a = scipy.signal.iirfilter(1, [128, 2048], btype=\"bandpass\", fs=sr_sound)\n",
    "\n",
    "    # apply the filter using `scipy.signal.lfilter`\n",
    "    y_sound_filt = scipy.signal.filtfilt(b, a, sound)\n",
    "    return y_sound_filt\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.6 ('speaker_recognition-4eUny3JK')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9646c40da97416857da782f9a77bcc8b7b553f48b96a3f511545e913842bf001"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
